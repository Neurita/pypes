{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from hansel import Crumb\n",
    "from hansel.operations import joint_value_map, valuesmap_to_dict\n",
    "import nipype.pipeline.engine as pe\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces import spm\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import DataSink\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "from nipype.interfaces.base import traits\n",
    "\n",
    "from neuro_pypes.crumb import DataCrumb\n",
    "from neuro_pypes.preproc.slicetime_params import STCParametersInterface\n",
    "from neuro_pypes.interfaces.nilearn import math_img\n",
    "from neuro_pypes.preproc import get_bounding_box\n",
    "from neuro_pypes.utils import (\n",
    "    remove_ext,\n",
    "    joinstrings,\n",
    "    selectindex\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_name = 'spm_rest_preprocessing'\n",
    "\n",
    "work_dir = os.path.expanduser(f'~/data/neuro_pypes/{wf_name}/')\n",
    "output_dir = os.path.join(work_dir, 'out')\n",
    "cache_dir = os.path.join(work_dir, 'wd')\n",
    "\n",
    "input_dir = os.path.expanduser('~/projects/neuro/multimodal_test_data/raw')\n",
    "\n",
    "data_path = os.path.join(os.path.expanduser(input_dir), '{subject_id}', '{session}', '{image}')\n",
    "data_crumb = Crumb(data_path, ignore_list=['.*'])\n",
    "crumb_modalities = {\n",
    "    'anat': [('image', 'anat.nii.gz')],\n",
    "    'fmri': [('image', 'rest.nii.gz')]\n",
    "}\n",
    "\n",
    "anat_voxel_sizes = [1, 1, 1]\n",
    "\n",
    "fmri_smoothing_kernel_fwhm = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = pe.Workflow(name=wf_name, base_dir=work_dir)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# DATA INPUT AND SINK\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "datasource = pe.Node(\n",
    "    DataCrumb(crumb=data_crumb, templates=crumb_modalities, raise_on_empty=False),\n",
    "    name='selectfiles'\n",
    ")\n",
    "\n",
    "datasink = pe.Node(\n",
    "    DataSink(parameterization=False, base_directory=output_dir, ),\n",
    "    name=\"datasink\"\n",
    ")\n",
    "    \n",
    "# basic file name substitutions for the datasink\n",
    "undef_args = datasource.interface._infields\n",
    "substitutions = [(name, \"\") for name in undef_args]\n",
    "substitutions.append((\"__\", \"_\"))\n",
    "\n",
    "datasink.inputs.substitutions = extend_trait_list(datasink.inputs.substitutions, substitutions)\n",
    "\n",
    "# Infosource - the information source that iterates over crumb values map from the filesystem\n",
    "infosource = pe.Node(interface=IdentityInterface(fields=undef_args), name=\"infosrc\")\n",
    "infosource.iterables = list(valuesmap_to_dict(joint_value_map(data_crumb, undef_args)).items())\n",
    "infosource.synchronize = True\n",
    "\n",
    "# connect the input_wf to the datasink\n",
    "joinpath = pe.Node(joinstrings(len(undef_args)), name='joinpath')\n",
    "\n",
    "# Connect the infosrc node to the datasink\n",
    "input_joins = [(name, 'arg{}'.format(arg_no + 1)) for arg_no, name in enumerate(undef_args)]\n",
    "\n",
    "wf.connect([\n",
    "    (infosource, datasource, [(field, field) for field in undef_args]),\n",
    "    (datasource, joinpath, input_joins),\n",
    "    (joinpath, datasink, [(\"out\", \"container\")]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------\n",
    "# ANAT\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# T1 preprocessing nodes\n",
    "\n",
    "# ANTs N4 Bias field correction\n",
    "n4 = N4BiasFieldCorrection()\n",
    "n4.inputs.dimension = 3\n",
    "n4.inputs.bspline_fitting_distance = 300\n",
    "n4.inputs.shrink_factor = 3\n",
    "n4.inputs.n_iterations = [50, 50, 30, 20]\n",
    "n4.inputs.convergence_threshold = 1e-6\n",
    "n4.inputs.save_bias = True\n",
    "n4.inputs.input_image = traits.Undefined\n",
    "biascor = pe.Node(n4, name=\"bias_correction\")\n",
    "\n",
    "gunzip_anat = pe.Node(Gunzip(), name=\"gunzip_anat\")\n",
    "\n",
    "# SPM New Segment\n",
    "spm_info = spm.Info()\n",
    "priors_path = os.path.join(spm_info.path(), 'tpm', 'TPM.nii')\n",
    "segment = spm.NewSegment()\n",
    "tissue1 = ((priors_path, 1), 1, (True,  True),   (True,  True))\n",
    "tissue2 = ((priors_path, 2), 1, (True,  True),   (True,  True))\n",
    "tissue3 = ((priors_path, 3), 2, (True,  True),   (True,  True))\n",
    "tissue4 = ((priors_path, 4), 3, (True,  True),   (True,  True))\n",
    "tissue5 = ((priors_path, 5), 4, (True,  False),  (False, False))\n",
    "tissue6 = ((priors_path, 6), 2, (False, False),  (False, False))\n",
    "segment.inputs.tissues = [tissue1, tissue2, tissue3, tissue4, tissue5, tissue6]\n",
    "segment.inputs.channel_info = (0.0001, 60, (True, True))\n",
    "segment.inputs.write_deformation_fields = [True, True]\n",
    "segment.inputs.channel_files = traits.Undefined\n",
    "segment = pe.Node(segment, name=\"new_segment\")\n",
    "\n",
    "# Apply deformations\n",
    "normalize_anat = spm.Normalize12(jobtype='write')\n",
    "normalize_anat.inputs.write_voxel_sizes = anat_voxel_sizes\n",
    "normalize_anat.inputs.deformation_file = traits.Undefined\n",
    "normalize_anat.inputs.image_to_align = traits.Undefined\n",
    "normalize_anat.inputs.write_bounding_box = traits.Undefined\n",
    "warp_anat = pe.Node(normalize_anat, name=\"warp_anat\")\n",
    "\n",
    "tpm_bbox = pe.Node(\n",
    "    Function(function=get_bounding_box, input_names=[\"in_file\"], output_names=[\"bbox\"]),\n",
    "    name=\"tpm_bbox\"\n",
    ")\n",
    "tpm_bbox.inputs.in_file = priors_path\n",
    "\n",
    "# calculate brain mask from tissue maps\n",
    "tissues = pe.Node(\n",
    "    IdentityInterface(fields=[\"gm\", \"wm\", \"csf\"], mandatory_inputs=True),\n",
    "    name=\"tissues\"\n",
    ")\n",
    "brain_mask = pe.Node(\n",
    "    Function(\n",
    "        function=math_img, \n",
    "        input_names=[\"formula\", \"out_file\", \"gm\", \"wm\", \"csf\"], \n",
    "        output_names=[\"out_file\"],\n",
    "        imports=['from neuro_pypes.interfaces.nilearn import ni2file']),\n",
    "        name='brain_mask'\n",
    ")\n",
    "brain_mask.inputs.out_file = \"tissues_brain_mask.nii.gz\"\n",
    "brain_mask.inputs.formula  = \"np.abs(gm + wm + csf) > 0\"\n",
    "\n",
    "# Connect the nodes\n",
    "wf.connect([\n",
    "    # input to biasfieldcorrection\n",
    "    (datasource, biascor, [(\"anat\", \"input_image\")]),\n",
    "\n",
    "    # new segment\n",
    "    (biascor,      gunzip_anat, [(\"output_image\", \"in_file\")]),\n",
    "    (gunzip_anat,  segment,     [(\"out_file\",     \"channel_files\")]),\n",
    "\n",
    "    # Normalize12\n",
    "    (segment,   warp_anat,  [(\"forward_deformation_field\", \"deformation_file\")]),\n",
    "    (segment,   warp_anat,  [(\"bias_corrected_images\",     \"apply_to_files\")]),\n",
    "    (tpm_bbox,  warp_anat,  [(\"bbox\",                      \"write_bounding_box\")]),\n",
    "\n",
    "    # brain mask from tissues\n",
    "    (segment, tissues,[\n",
    "        ((\"native_class_images\", selectindex, 0), \"gm\"),\n",
    "        ((\"native_class_images\", selectindex, 1), \"wm\"),\n",
    "        ((\"native_class_images\", selectindex, 2), \"csf\"),\n",
    "    ]),\n",
    "\n",
    "    (tissues, brain_mask, [(\"gm\", \"gm\"), (\"wm\", \"wm\"), (\"csf\", \"csf\"),]),\n",
    "\n",
    "    # output\n",
    "    (warp_anat, datasink,  [(\"normalized_files\",           \"anat.@mni\")]),\n",
    "    (segment,   datasink,  [(\"modulated_class_images\",     \"anat.tissues.warped\"),\n",
    "                            (\"native_class_images\",        \"anat.tissues.native\"),\n",
    "                            (\"transformation_mat\",         \"anat.transform.@linear\"),\n",
    "                            (\"forward_deformation_field\",  \"anat.transform.@forward\"),\n",
    "                            (\"inverse_deformation_field\",  \"anat.transform.@inverse\"),\n",
    "                            (\"bias_corrected_images\",      \"anat.@biascor\")]),\n",
    "    (brain_mask, datasink, [(\"out_file\",                   \"anat.@brain_mask\")]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------\n",
    "# FMRI Clean\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# rs-fMRI preprocessing nodes\n",
    "trim = pe.Node(Trim(), name=\"trim\")\n",
    "\n",
    "# slice-timing correction\n",
    "params = setup_node(STCParametersInterface(in_files=in_file), name='stc_params')\n",
    "gunzip = setup_node(Gunzip(), name=\"gunzip\")\n",
    "\n",
    "stc = spm.SliceTiming()\n",
    "stc.inputs.in_files = traits.Undefined\n",
    "stc.inputs.out_prefix = 'stc'\n",
    "slice_timing = pe.Node(stc, name='slice_timing')\n",
    "wf.connect([(stc_input, params, [(\"in_file\",          \"in_files\"),\n",
    "                                 (\"num_slices\",       \"num_slices\"),\n",
    "                                 (\"slice_order\",      \"slice_order\"),\n",
    "                                 (\"time_repetition\",  \"time_repetition\"),\n",
    "                                 (\"time_acquisition\", \"time_acquisition\"),\n",
    "                                 (\"ref_slice\",        \"ref_slice\"),\n",
    "                                 (\"slice_mode\",       \"slice_mode\"),\n",
    "                                 ]),\n",
    "\n",
    "            # processing nodes\n",
    "            (params, gunzip,    [((\"in_files\",    _pick_first),      \"in_file\")]),\n",
    "            (params, stc,       [((\"slice_order\", _sum_one_to_each), \"slice_order\"),\n",
    "                                 ((\"ref_slice\",   _sum_one),         \"ref_slice\"),\n",
    "                                 (\"num_slices\",                      \"num_slices\"),\n",
    "                                 (\"time_acquisition\",                \"time_acquisition\"),\n",
    "                                 (\"time_repetition\",                 \"time_repetition\"),\n",
    "                                 ]),\n",
    "            (gunzip, stc,       [(\"out_file\",                        \"in_files\")]),\n",
    "\n",
    "            # output node\n",
    "            (params, stc_output, [(\"time_repetition\", \"time_repetition\")]),\n",
    "            (stc,    stc_output, [(\"timecorrected_files\", \"timecorrected_files\")]),\n",
    "            ])\n",
    "\n",
    "\n",
    "realign = pe.Node(nipy_motion_correction(), name='realign')\n",
    "\n",
    "# average\n",
    "average = pe.Node(\n",
    "    Function(\n",
    "        function=mean_img,\n",
    "        input_names=[\"in_file\"],\n",
    "        output_names=[\"out_file\"],\n",
    "        imports=['from neuro_pypes.interfaces.nilearn import ni2file']\n",
    "    ),\n",
    "    name='average_epi'\n",
    ")\n",
    "\n",
    "mean_gunzip = pe.Node(Gunzip(), name=\"mean_gunzip\")\n",
    "\n",
    "# co-registration nodes\n",
    "coreg = pe.Node(spm_coregister(cost_function=\"mi\"), name=\"coreg_fmri\")\n",
    "brain_sel = pe.Node(Select(index=[0, 1, 2]), name=\"brain_sel\")\n",
    "\n",
    "# brain mask made with EPI\n",
    "epi_mask = pe.Node(ComputeMask(), name='epi_mask')\n",
    "\n",
    "# brain mask made with the merge of the tissue segmentations\n",
    "tissue_mask = pe.Node(fsl.MultiImageMaths(), name='tissue_mask')\n",
    "tissue_mask.inputs.op_string = \"-add %s -add %s -abs -kernel gauss 4 -dilM -ero -kernel gauss 1 -dilM -bin\"\n",
    "tissue_mask.inputs.out_file = \"tissue_brain_mask.nii.gz\"\n",
    "\n",
    "# select tissues\n",
    "gm_select = pe.Node(Select(index=[0]), name=\"gm_sel\")\n",
    "wmcsf_select = pe.Node(Select(index=[1, 2]), name=\"wmcsf_sel\")\n",
    "\n",
    "# noise filter\n",
    "noise_wf = rest_noise_filter_wf()\n",
    "wm_select = pe.Node(Select(index=[1]), name=\"wm_sel\")\n",
    "csf_select = pe.Node(Select(index=[2]), name=\"csf_sel\")\n",
    "\n",
    "# bandpass filtering\n",
    "bandpass = pe.Node(\n",
    "    Function(\n",
    "        input_names=['files', 'lowpass_freq', 'highpass_freq', 'tr'],\n",
    "        output_names=['out_files'],\n",
    "        function=bandpass_filter\n",
    "    ),\n",
    "    name='bandpass'\n",
    ")\n",
    "\n",
    "# smooth\n",
    "smooth = pe.Node(\n",
    "    Function(\n",
    "        function=smooth_img,\n",
    "        input_names=[\"in_file\", \"fwhm\"],\n",
    "        output_names=[\"out_file\"],\n",
    "        imports=['from neuro_pypes.interfaces.nilearn import ni2file']\n",
    "    ),\n",
    "    name=\"smooth\"\n",
    ")\n",
    "smooth.inputs.fwhm = fmri_smoothing_kernel_fwhm\n",
    "smooth.inputs.out_file = \"smooth_std_{}.nii.gz\".format(wf_name)\n",
    "\n",
    "# output identities\n",
    "rest_output = setup_node(IdentityInterface(fields=out_fields), name=\"rest_output\")\n",
    "\n",
    "# Connect the nodes\n",
    "\n",
    "# (in_files, cleanup_wf, [(\"rest\", \"rest_input.in_file\")]),\n",
    "\n",
    "# # anat to fMRI registration inputs\n",
    "# (anat_output, cleanup_wf, [\n",
    "#     (\"tissues_native\", \"rest_input.tissues\"),\n",
    "#     (\"anat_biascorr\", \"rest_input.anat\"),\n",
    "# ]),\n",
    "\n",
    "# # clean_up_wf to datasink\n",
    "# (cleanup_wf, datasink, [\n",
    "#     (\"rest_output.epi_brain_mask\", \"rest.@epi_brain_mask\"),\n",
    "#     (\"rest_output.tissues_brain_mask\", \"rest.@tissues_brain_mask\"),\n",
    "#     (\"rest_output.tissues\", \"rest.@tissues\"),\n",
    "#     (\"rest_output.anat\", \"rest.@anat\"),\n",
    "#     (\"rest_output.motion_regressors\", \"rest.@motion_regressors\"),\n",
    "#     (\"rest_output.compcor_regressors\", \"rest.@compcor_regressors\"),\n",
    "#     (\"rest_output.gsr_regressors\", \"rest.@gsr_regressors\"),\n",
    "#     (\"rest_output.motion_params\", \"rest.@motion_params\"),\n",
    "#     (\"rest_output.motion_corrected\", \"rest.@motion_corrected\"),\n",
    "#     (\"rest_output.nuis_corrected\", \"rest.@nuis_corrected\"),\n",
    "#     (\"rest_output.time_filtered\", \"rest.@time_filtered\"),\n",
    "#     (\"rest_output.smooth\", \"rest.@smooth\"),\n",
    "#     (\"rest_output.avg_epi\", \"rest.@avg_epi\"),\n",
    "#     (\"rest_output.tsnr_file\", \"rest.@tsnr\"),\n",
    "#     (\"rest_output.art_displacement_files\", \"rest.artifact_stats.@displacement\"),\n",
    "#     (\"rest_output.art_intensity_files\", \"rest.artifact_stats.@art_intensity\"),\n",
    "#     (\"rest_output.art_norm_files\", \"rest.artifact_stats.@art_norm\"),\n",
    "#     (\"rest_output.art_outlier_files\", \"rest.artifact_stats.@art_outlier\"),\n",
    "#     (\"rest_output.art_plot_files\", \"rest.artifact_stats.@art_plot\"),\n",
    "#     (\"rest_output.art_statistic_files\", \"rest.artifact_stats.@art_statistic\"),\n",
    "# ]),\n",
    "# ])\n",
    "\n",
    "wf.connect([\n",
    "    # trim\n",
    "    (rest_input, trim, [(\"in_file\", \"in_file\")]),\n",
    "\n",
    "    # slice time correction\n",
    "    (trim, stc_wf, [(\"out_file\", \"stc_input.in_file\")]),\n",
    "\n",
    "    # motion correction\n",
    "    (stc_wf, realign, [(\"stc_output.timecorrected_files\", \"in_file\")]),\n",
    "\n",
    "    # coregistration target\n",
    "    (realign, average, [(\"out_file\", \"in_file\")]),\n",
    "    (average, mean_gunzip, [(\"out_file\", \"in_file\")]),\n",
    "    (mean_gunzip, coreg, [(\"out_file\", \"target\")]),\n",
    "\n",
    "    # epi brain mask\n",
    "    (average, epi_mask, [(\"out_file\", \"mean_volume\")]),\n",
    "\n",
    "    # coregistration\n",
    "    (rest_input, coreg, [(\"anat\", \"source\")]),\n",
    "    (rest_input, brain_sel, [(\"tissues\", \"inlist\")]),\n",
    "    (brain_sel, coreg, [((\"out\", flatten_list), \"apply_to_files\")]),\n",
    "\n",
    "    # tissue brain mask\n",
    "    (coreg, gm_select, [(\"coregistered_files\", \"inlist\")]),\n",
    "    (coreg, wmcsf_select, [(\"coregistered_files\", \"inlist\")]),\n",
    "    (gm_select, tissue_mask, [((\"out\", flatten_list), \"in_file\")]),\n",
    "    (wmcsf_select, tissue_mask, [((\"out\", flatten_list), \"operand_files\")]),\n",
    "\n",
    "    # nuisance correction\n",
    "    (coreg, wm_select, [(\"coregistered_files\", \"inlist\",)]),\n",
    "    (coreg, csf_select, [(\"coregistered_files\", \"inlist\",)]),\n",
    "    (realign, noise_wf, [(\"out_file\", \"rest_noise_input.in_file\",)]),\n",
    "    (tissue_mask, noise_wf, [(\"out_file\", \"rest_noise_input.brain_mask\")]),\n",
    "    (wm_select, noise_wf, [((\"out\", flatten_list), \"rest_noise_input.wm_mask\")]),\n",
    "    (csf_select, noise_wf, [((\"out\", flatten_list), \"rest_noise_input.csf_mask\")]),\n",
    "\n",
    "    (realign, noise_wf, [(\"par_file\", \"rest_noise_input.motion_params\",)]),\n",
    "\n",
    "    # temporal filtering\n",
    "    (noise_wf, bandpass, [(\"rest_noise_output.nuis_corrected\", \"files\")]),\n",
    "    # (realign,     bandpass,    [(\"out_file\", \"files\")]),\n",
    "    (stc_wf, bandpass, [(\"stc_output.time_repetition\", \"tr\")]),\n",
    "    (rest_input, bandpass, [\n",
    "        (\"lowpass_freq\", \"lowpass_freq\"),\n",
    "        (\"highpass_freq\", \"highpass_freq\"),\n",
    "    ]),\n",
    "    (bandpass, smooth, [(\"out_files\", \"in_file\")]),\n",
    "\n",
    "    # output\n",
    "    (epi_mask, rest_output, [(\"brain_mask\", \"epi_brain_mask\")]),\n",
    "    (tissue_mask, rest_output, [(\"out_file\", \"tissues_brain_mask\")]),\n",
    "    (realign, rest_output, [\n",
    "        (\"out_file\", \"motion_corrected\"),\n",
    "        (\"par_file\", \"motion_params\"),\n",
    "    ]),\n",
    "    (coreg, rest_output, [\n",
    "        (\"coregistered_files\", \"tissues\"),\n",
    "        (\"coregistered_source\", \"anat\"),\n",
    "    ]),\n",
    "    (noise_wf, rest_output, [\n",
    "        (\"rest_noise_output.motion_regressors\", \"motion_regressors\"),\n",
    "        (\"rest_noise_output.compcor_regressors\", \"compcor_regressors\"),\n",
    "        (\"rest_noise_output.gsr_regressors\", \"gsr_regressors\"),\n",
    "        (\"rest_noise_output.nuis_corrected\", \"nuis_corrected\"),\n",
    "        (\"rest_noise_output.tsnr_file\", \"tsnr_file\"),\n",
    "        (\"rest_noise_output.art_displacement_files\", \"art_displacement_files\"),\n",
    "        (\"rest_noise_output.art_intensity_files\", \"art_intensity_files\"),\n",
    "        (\"rest_noise_output.art_norm_files\", \"art_norm_files\"),\n",
    "        (\"rest_noise_output.art_outlier_files\", \"art_outlier_files\"),\n",
    "        (\"rest_noise_output.art_plot_files\", \"art_plot_files\"),\n",
    "        (\"rest_noise_output.art_statistic_files\", \"art_statistic_files\"),\n",
    "    ]),\n",
    "    (average, rest_output, [(\"out_file\", \"avg_epi\")]),\n",
    "    (bandpass, rest_output, [(\"out_files\", \"time_filtered\")]),\n",
    "    (smooth, rest_output, [(\"out_file\", \"smooth\")]),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_cpus > 1:\n",
    "    wf.run(plugin=plugin, plugin_args={\"n_procs\": n_cpus})\n",
    "else:\n",
    "    wf.run(plugin=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
